{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a267c89",
   "metadata": {},
   "source": [
    "# Qubit Mover 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db34abb",
   "metadata": {},
   "source": [
    "Qubit Mover 2.0 is an updated version of the Qubit Mover project, which aims to develop a reinforcement learning agent capable of optimizing qubit distribution protocols in a quantum network. The agent will learn to navigate the network and make decisions that maximize the quantum Fisher information matrix (QFIM) for parameter estimation tasks. In addition to being able to move qubits, the agent will also have the ability to apply hadamard gates to qubits, allowing for more complex state manipulations and potentially improving the estimation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4bf9f",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "This section imports all the required libraries for quantum information calculations, symbolic computation, reinforcement learning, and plotting. Each library is chosen for its specific capabilities:\n",
    "- `itertools`, `random`, `datetime`: Standard Python utilities for combinatorics, randomness, and time-stamping.\n",
    "- `sympy`: Used for symbolic mathematics, which is essential for quantum Fisher information and protocol analysis.\n",
    "- `numpy`: Efficient numerical operations and array handling.\n",
    "- `matplotlib`: For visualizing results and protocol performance.\n",
    "- `gymnasium`, `stable_baselines3`: RL environment and agent training.\n",
    "- `scipy.optimize`: For numerical root finding and least squares estimation in parameter recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e5f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QFIM calculations libraries\n",
    "from itertools import combinations\n",
    "\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "# Estimator libraries\n",
    "from scipy.optimize import root, least_squares\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RL libraries\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c583e",
   "metadata": {},
   "source": [
    "## Create Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b66a7c",
   "metadata": {},
   "source": [
    "The density matrix of each qubit will be calculated seperately and symbolically using sympy. The overall density matrix will be the tensor product of each qubit's density matrix. The QFIM will then be calculated from the overall density matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26be9ad",
   "metadata": {},
   "source": [
    "### Initialize Constants and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57f3537",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state0\u001b[38;5;241m=\u001b[39m\u001b[43msp\u001b[49m\u001b[38;5;241m.\u001b[39mMatrix(np\u001b[38;5;241m.\u001b[39mmatrix([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m],[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m      2\u001b[0m x_gate\u001b[38;5;241m=\u001b[39msp\u001b[38;5;241m.\u001b[39mMatrix(np\u001b[38;5;241m.\u001b[39mmatrix([[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m      3\u001b[0m h_gate\u001b[38;5;241m=\u001b[39msp\u001b[38;5;241m.\u001b[39mMatrix(np\u001b[38;5;241m.\u001b[39mmatrix([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]))\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sp' is not defined"
     ]
    }
   ],
   "source": [
    "state0=sp.Matrix(np.matrix([[1,0],[0,0]]))\n",
    "x_gate=sp.Matrix(np.matrix([[0,1],[1,0]]))\n",
    "h_gate=sp.Matrix(np.matrix([[1,1],[1,-1]]))/np.sqrt(2)\n",
    "p1,p2,p3 = sp.symbols('p1 p2 p3') # Parameter symbols\n",
    "symbols_list = [p1,p2,p3]\n",
    "p1_hat,p2_hat,p3_hat = sp.symbols('p1_hat p2_hat p3_hat')\n",
    "\n",
    "def error_1(rho):\n",
    "    return(p1_hat*rho+p1*x_gate*rho*x_gate)\n",
    "\n",
    "def error_2(rho):\n",
    "    return(p2_hat*rho+p2*x_gate*rho*x_gate)\n",
    "\n",
    "def error_3(rho):\n",
    "    return(p3_hat*rho+p3*x_gate*rho*x_gate)\n",
    "\n",
    "def hadamard(rho):\n",
    "    return(h_gate*rho*h_gate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a534b2f",
   "metadata": {},
   "source": [
    "### Fisher Information Matrix Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb697b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⎡11.1111111111111   0           0        ⎤\n",
      "⎢                                        ⎥\n",
      "⎢       0          6.25         0        ⎥\n",
      "⎢                                        ⎥\n",
      "⎣       0           0    4.76190476190476⎦\n"
     ]
    }
   ],
   "source": [
    "def calculate_QFIM(rhos,thetas=None):\n",
    "\n",
    "    state0=sp.Matrix(np.matrix([[1,0],[0,0]]))\n",
    "    x_gate=sp.Matrix(np.matrix([[0,1],[1,0]]))\n",
    "    h_gate=sp.Matrix(np.matrix([[1,1],[1,-1]]))/np.sqrt(2)\n",
    "    p1,p2,p3 = sp.symbols('p1 p2 p3') # Parameter symbols\n",
    "    symbols_list = [p1,p2,p3]\n",
    "    p1_hat,p2_hat,p3_hat = sp.symbols('p1_hat p2_hat p3_hat')\n",
    "\n",
    "\n",
    "    # compute eigen values\n",
    "\n",
    "    F=sp.zeros(len(symbols_list), len(symbols_list))\n",
    "    n=len(symbols_list)\n",
    "\n",
    "    for rho in rhos:\n",
    "\n",
    "        lambdas=rho.eigenvals()\n",
    "\n",
    "\n",
    "        subs_dict = {sp.symbols('p1_hat'): 1 - sp.symbols('p1'),\n",
    "                    sp.symbols('p2_hat'): 1 - sp.symbols('p2'),\n",
    "                    sp.symbols('p3_hat'): 1 - sp.symbols('p3')}\n",
    "        lambdas_sub = [lam.subs(subs_dict) for lam in lambdas]\n",
    "\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                s = 0\n",
    "                for lam in lambdas_sub:\n",
    "                    if lam == 0:\n",
    "                        continue  # Skip zero eigenvalues to avoid division by zero\n",
    "                    s += (1/lam) * lam.diff(symbols_list[i]) * lam.diff(symbols_list[j])\n",
    "                F[i, j] += s\n",
    "\n",
    "\n",
    "    if thetas is not None:\n",
    "        F=F.subs({p1: thetas[0], p2: thetas[1], p3: thetas[2]})\n",
    "    return F\n",
    "\n",
    "rho1=hadamard(error_1(hadamard(error_1(state0))))\n",
    "rho2=hadamard(error_2(hadamard(error_2(state0))))\n",
    "rho3=error_3(hadamard(error_3(hadamard(state0))))\n",
    "\n",
    "\n",
    "sp.pprint(calculate_QFIM([rho1,rho2,rho3],thetas=[0.1,0.2,0.3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33e23f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.460000000000000\n"
     ]
    }
   ],
   "source": [
    "def calculate_QCRB(F):\n",
    "    return F.inv().trace()\n",
    "\n",
    "print(calculate_QCRB(calculate_QFIM([rho1,rho2,rho3],thetas=[0.1,0.2,0.3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fd6f4",
   "metadata": {},
   "source": [
    "### RLA Move Interpereter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc9b4396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 1, 1, 2, 4, 2, 3, 3, 1, 1, 4, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nodes_to_paths(move_list):\n",
    "    move_list = [x for x in move_list if x != 0]\n",
    "    node_list=[((n-1)//4)+1 for n in move_list] # Removes the hadamard gates from the list\n",
    "    #print(node_list)\n",
    "    h_list=[((n-1)%4) for n in move_list] # Extracts the hadamard gates from the list\n",
    "    #print(h_list)\n",
    "\n",
    "    path_list=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if h_list[0]==0:\n",
    "        path_list.append(node_list[0])\n",
    "    \n",
    "    elif h_list[0]==1:\n",
    "        path_list.append(4)\n",
    "        path_list.append(node_list[0])\n",
    "\n",
    "    elif h_list[0]==2:\n",
    "        path_list.append(node_list[0])\n",
    "        path_list.append(4)\n",
    "\n",
    "    elif h_list[0]==3:\n",
    "        path_list.append(4)\n",
    "        path_list.append(node_list[0])\n",
    "        path_list.append(4)\n",
    "\n",
    "    if len(node_list)<=1: # Ensures that single node lists are handled correctly\n",
    "        return -1 # Invalid single node list\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(1,len(node_list)):\n",
    "\n",
    "        if h_list[i]==0:\n",
    "            path_list.append(node_list[i])\n",
    "    \n",
    "        elif h_list[i]==1:\n",
    "            path_list.append(4)\n",
    "            path_list.append(node_list[i])\n",
    "\n",
    "        elif h_list[i]==2:\n",
    "            path_list.append(node_list[i])\n",
    "            path_list.append(4)\n",
    "\n",
    "        elif h_list[i]==3:\n",
    "            path_list.append(4)\n",
    "            path_list.append(node_list[i])\n",
    "            path_list.append(4)\n",
    "\n",
    "\n",
    "        path_list.append(node_list[i])\n",
    "\n",
    "    path_list.pop() \n",
    "\n",
    "    \n",
    "\n",
    "    return path_list\n",
    "\n",
    "    # return filtered_list\n",
    "\n",
    "\n",
    "nodes_to_paths([10,1,7,9,1,10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93620cc4",
   "metadata": {},
   "source": [
    "### Convert Moves into states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87a0b661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix([[p1*(0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) + 0.5*p3_hat*(p1*p2_hat + p1_hat*p2)) + p1_hat*(0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) + 0.5*p3_hat*(p1*p2_hat + p1_hat*p2)), p1*(-0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) - 0.5*p3_hat*(p1*p2_hat + p1_hat*p2)) + p1_hat*(-0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) - 0.5*p3_hat*(p1*p2_hat + p1_hat*p2))], [p1*(-0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) - 0.5*p3_hat*(p1*p2_hat + p1_hat*p2)) + p1_hat*(-0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) - 0.5*p3_hat*(p1*p2_hat + p1_hat*p2)), p1*(0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) + 0.5*p3_hat*(p1*p2_hat + p1_hat*p2)) + p1_hat*(0.5*p3*(p1*p2 + p1_hat*p2_hat) + 0.5*p3*(p1*p2_hat + p1_hat*p2) + 0.5*p3_hat*(p1*p2 + p1_hat*p2_hat) + 0.5*p3_hat*(p1*p2_hat + p1_hat*p2))]])\n"
     ]
    }
   ],
   "source": [
    "def moves_to_gates(move_list):\n",
    "    state0 = sp.Matrix([[1, 0], [0, 0]])\n",
    "    temp_rho=state0 # Initialize the qubit in the 0 state\n",
    "    x_gate=sp.Matrix(np.matrix([[0,1],[1,0]]))\n",
    "    h_gate=sp.Matrix(np.matrix([[1,1],[1,-1]]))/np.sqrt(2)\n",
    "    p1,p2,p3 = sp.symbols('p1 p2 p3') # Parameter symbols\n",
    "    symbols_list = [p1,p2,p3]\n",
    "    p1_hat,p2_hat,p3_hat = sp.symbols('p1_hat p2_hat p3_hat')\n",
    "    \n",
    "    for move in move_list:\n",
    "        if move == 1:\n",
    "            temp_rho=(p1_hat*temp_rho+p1*x_gate*temp_rho*x_gate)\n",
    "        elif move == 2:\n",
    "            temp_rho=(p2_hat*temp_rho+p2*x_gate*temp_rho*x_gate)\n",
    "        elif move == 3:\n",
    "            temp_rho=(p3_hat*temp_rho+p3*x_gate*temp_rho*x_gate)\n",
    "        elif move == 4:\n",
    "            temp_rho=h_gate*temp_rho*h_gate\n",
    "        else:\n",
    "            #print(\"Invalid move detected\")\n",
    "            return -10\n",
    "        temp_rho=sp.Matrix(temp_rho)\n",
    "    return temp_rho\n",
    "\n",
    "print(moves_to_gates([1,2,3,4,1]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30538667",
   "metadata": {},
   "source": [
    "### Create the reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c176d4",
   "metadata": {},
   "source": [
    "#### Reward function to help learn the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "388359f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_easy(node_lists,thetas):\n",
    "    \" Reward function that gives a large negative reward for invalid paths, and otherwise rewards based on QCRB improvement\"\n",
    "    for node_list in node_lists:\n",
    "        counter=0\n",
    "        if node_list[0]==0 or node_list[1]==0 or node_list[-1]!=0:\n",
    "            counter+=1\n",
    "            #print(\"Yikes\")\n",
    "        \n",
    "        found_zero = False\n",
    "        for val in node_list:\n",
    "            if val == 0:\n",
    "                found_zero = True\n",
    "            elif found_zero and val != 0:\n",
    "                #print(\"Invalid: nonzero after zero\")\n",
    "                counter+=1  # or any large negative reward\n",
    "            \n",
    "    if counter>0:\n",
    "        return -counter # Large negative reward for invalid input\n",
    "    \n",
    "\n",
    "    # Make sure there are an even number of hadamard gates between nodes\n",
    "    path_lists=[]\n",
    "    for node_list in node_lists:\n",
    "        path_list=nodes_to_paths(node_list)\n",
    "        if path_list == -1:\n",
    "            \n",
    "            #print(\"Invalid first move\")\n",
    "            return -1 # Invalid path due to invalid first move\n",
    "            \n",
    "        elif path_list.count(4) % 2 != 0:\n",
    "            #print(\"Odd hadamards\")\n",
    "            return -.5 # Invalid path due to odd number of hadamards\n",
    "        \n",
    "        path_lists.append(path_list)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83cd92",
   "metadata": {},
   "source": [
    "#### Reward Function for protocol optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d660ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(node_lists,thetas):\n",
    "\n",
    "    #################################\n",
    "    ## Make sure the protocol is valid\n",
    "    #################################\n",
    "\n",
    "    # Make sure that the first element is not 0 and the last element is 0\n",
    "    for node_list in node_lists:\n",
    "        if node_list[0]==0 or node_list[1]==0 or node_list[-1]!=0:\n",
    "            #print(\"Yikes\")\n",
    "            return -10 # Large negative reward for invalid input\n",
    "        found_zero = False\n",
    "        for val in node_list:\n",
    "            if val == 0:\n",
    "                found_zero = True\n",
    "            elif found_zero and val != 0:\n",
    "                #print(\"Invalid: nonzero after zero\")\n",
    "                return -10  # or any large negative reward\n",
    "            \n",
    "    # Make sure there are an even number of hadamard gates between nodes\n",
    "    path_lists=[]\n",
    "    for node_list in node_lists:\n",
    "        path_list=nodes_to_paths(node_list)\n",
    "        if path_list == -1:\n",
    "            \n",
    "            #print(\"Invalid first move\")\n",
    "            return -10 # Invalid path due to invalid first move\n",
    "            \n",
    "        elif path_list.count(4) % 2 != 0:\n",
    "            #print(\"Odd hadamards\")\n",
    "            return -10 # Invalid path due to odd number of hadamards\n",
    "        \n",
    "        path_lists.append(path_list)\n",
    "   \n",
    "    ################################\n",
    "    ## Calculate the QFIM\n",
    "    #################################\n",
    "    \n",
    "    rho_1=moves_to_gates(path_lists[0])\n",
    "    rho_2=moves_to_gates(path_lists[1])\n",
    "    rho_3=moves_to_gates(path_lists[2])\n",
    "    \n",
    "    \n",
    "    F=calculate_QFIM([rho_1,rho_2,rho_3],thetas=thetas) # Calculate the QFIM for the given states and parameters\n",
    "\n",
    "    #sp.pprint(F)\n",
    "\n",
    "    try:\n",
    "        qcrb= calculate_QCRB(F)\n",
    "        max_qcrb = 10.0\n",
    "        reward_val=1-qcrb/max_qcrb # Higher reward for lower qcrb, normalized between 0 and 1\n",
    "        reward_val = np.clip(reward_val, 0, 1)  # Ensure reward is within [0, 1]\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If F is singular or not invertible, give a large negative reward\n",
    "        reward_val = -10\n",
    "\n",
    "    return float(reward_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952cc57",
   "metadata": {},
   "source": [
    "#### Test the reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271888cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 3, 4, 3, 1]\n",
      "[4, 2, 4, 2]\n",
      "[4, 1, 1, 4]\n",
      "-10\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "thetas=[0.1,0.2,0.3]\n",
    "## Catch invalid moves\n",
    "p1=[10,11,0,0,0,0]\n",
    "p2=[6,6,0,0,0,0]\n",
    "p3=[2,3,0,0,0,0]\n",
    "\n",
    "print(nodes_to_paths(p1))\n",
    "print(nodes_to_paths(p2))\n",
    "print(nodes_to_paths(p3))\n",
    "\n",
    "print(reward([p1,p2,p3],thetas))\n",
    "print(reward_function_easy([p1,p2,p3],thetas))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae80dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74b72bfb",
   "metadata": {},
   "source": [
    "## Train the RL Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097307e",
   "metadata": {},
   "source": [
    "### Create the environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206841c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QubitMoverEnv_easy(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Environment for the Qubit Mover RL agent.\n",
    "    - 3 qubits, each with a path of length 10\n",
    "    - Each step, the agent selects a node (1-3) or 0 (measure) for each qubit as well as whether to apply a hadamard gate (4)\n",
    "    - Episode ends after a fixed number of steps or when all qubits are measured\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_qubits = 3\n",
    "        self.max_steps = 10\n",
    "        self.thetas = np.random.uniform(0.05, 0.5, 3).tolist()\n",
    "\n",
    "        # Each qubit can be at node 0, 1, 2, or 3 at each step\n",
    "        self.action_space = spaces.MultiDiscrete([3] * self.n_qubits)\n",
    "\n",
    "\n",
    "        # Observation space: qubit states + theta values\n",
    "        # Qubit states: (n_qubits * max_steps), Theta: (3,)\n",
    "        low = np.zeros(self.n_qubits * self.max_steps + 3)\n",
    "        high = np.concatenate([np.full(self.n_qubits * self.max_steps, 13), np.ones(3)])\n",
    "        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.thetas = np.random.uniform(0.05, 0.5, 3).tolist() \n",
    "        self.state = np.zeros((self.n_qubits, self.max_steps), dtype=np.int32)\n",
    "        self.state=self.state.flatten()\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        obs = np.concatenate([self.state, np.array(self.thetas, dtype=np.float32)]).astype(np.float32)\n",
    "        return obs, {}\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise RuntimeError(\"Episode is done\")\n",
    "\n",
    "        # Record the action for each qubit at this step\n",
    "        # Update the observation space\n",
    "        for q in range(self.n_qubits):\n",
    "            self.state[q * self.max_steps + self.current_step] = action[q]\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        # If all qubits have been measured (0) or max_steps reached, episode is done\n",
    "        state_2d = self.state.reshape(self.n_qubits, self.max_steps)\n",
    "        all_measured = np.all(state_2d[:, self.current_step-1] == 0)\n",
    "\n",
    "        self.done = all_measured or self.current_step >= self.max_steps\n",
    "\n",
    "        reward_val = 0\n",
    "        \n",
    "        # The reward is only calculated at the end of the episode\n",
    "        if self.done:\n",
    "            # Convert state to list of lists for your reward function\n",
    "            node_lists = [list(state_2d[q]) for q in range(self.n_qubits)]\n",
    "            reward_val = reward_function_easy(node_lists, self.thetas)\n",
    "            reward_val+=0.5\n",
    "        else:\n",
    "            if self.current_step == 1 and np.any(((np.array(action) - 1) % 4 != 0) & ((np.array(action) - 1) % 4 != 1)):\n",
    "\n",
    "                reward_val = -1  # Or a step penalty if desired\n",
    "                self.done=True\n",
    "\n",
    "            if self.current_step == 1 and not action.all():\n",
    "                \n",
    "                reward_val = -1\n",
    "                self.done=True\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.state=self.state.flatten()\n",
    "        obs = np.concatenate([self.state, np.array(self.thetas, dtype=np.float32)]).astype(np.float32)\n",
    "\n",
    "        return obs.copy(), reward_val, self.done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(\"Step:\", self.current_step)\n",
    "        print(\"State:\\n\", self.state)\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Example usage:\n",
    "# env = QubitMoverEnv()\n",
    "# obs, info = env.reset()\n",
    "# done = False\n",
    "# while not done:\n",
    "#     action = env.action_space.sample()\n",
    "#     obs, reward, done, truncated, info = env.step(action)\n",
    "#     env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0021b12",
   "metadata": {},
   "source": [
    "#### Harder Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14045b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QubitMoverEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Environment for the Qubit Mover RL agent.\n",
    "    - 3 qubits, each with a path of length 10\n",
    "    - Each step, the agent selects a node (1-3) or 0 (measure) for each qubit as well as whether to apply a hadamard gate (4)\n",
    "    - Episode ends after a fixed number of steps or when all qubits are measured\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_qubits = 3\n",
    "        self.max_steps = 10\n",
    "        self.thetas = np.random.uniform(0.05, 0.5, 3).tolist()\n",
    "\n",
    "        # Each qubit can be at node 0, 1, 2, or 3 at each step\n",
    "        self.action_space = spaces.MultiDiscrete([13] * self.n_qubits)\n",
    "\n",
    "\n",
    "        # Observation space: qubit states + theta values\n",
    "        # Qubit states: (n_qubits * max_steps), Theta: (3,)\n",
    "        low = np.zeros(self.n_qubits * self.max_steps + 3)\n",
    "        high = np.concatenate([np.full(self.n_qubits * self.max_steps, 13), np.ones(3)])\n",
    "        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.thetas = np.random.uniform(0.05, 0.5, 3).tolist() \n",
    "        self.state = np.zeros((self.n_qubits, self.max_steps), dtype=np.int32)\n",
    "        self.state=self.state.flatten()\n",
    "        self.current_step = 0\n",
    "        self.done = False\n",
    "        obs = np.concatenate([self.state, np.array(self.thetas, dtype=np.float32)]).astype(np.float32)\n",
    "        return obs, {}\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # action: array of length 3, each in {0,1,2,3}\n",
    "        if self.done:\n",
    "            raise RuntimeError(\"Episode is done\")\n",
    "\n",
    "        # Record the action for each qubit at this step\n",
    "        # Update the observation space\n",
    "        for q in range(self.n_qubits):\n",
    "            self.state[q * self.max_steps + self.current_step] = action[q]\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        # If all qubits have been measured (0) or max_steps reached, episode is done\n",
    "        state_2d = self.state.reshape(self.n_qubits, self.max_steps)\n",
    "        all_measured = np.all(state_2d[:, self.current_step-1] == 0)\n",
    "\n",
    "        self.done = all_measured or self.current_step >= self.max_steps\n",
    "\n",
    "        reward_val = 0\n",
    "        \n",
    "        # The reward is only calculated at the end of the episode\n",
    "        if self.done:\n",
    "            # Convert state to list of lists for your reward function\n",
    "            node_lists = [list(state_2d[q]) for q in range(self.n_qubits)]\n",
    "            reward_val = reward(node_lists, self.thetas)\n",
    "        else:\n",
    "            reward_val = 0  # Or a step penalty if desired\n",
    "\n",
    "        self.state=self.state.flatten()\n",
    "        obs = np.concatenate([self.state, np.array(self.thetas, dtype=np.float32)]).astype(np.float32)\n",
    "\n",
    "        return obs.copy(), reward_val, self.done, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(\"Step:\", self.current_step)\n",
    "        print(\"State:\\n\", self.state)\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# Example usage:\n",
    "# env = QubitMoverEnv()\n",
    "# obs, info = env.reset()\n",
    "# done = False\n",
    "# while not done:\n",
    "#     action = env.action_space.sample()\n",
    "#     obs, reward, done, truncated, info = env.step(action)\n",
    "#     env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a359b",
   "metadata": {},
   "source": [
    "#### Verify the environment works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11cf7f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Environment check passed!\n",
      "Easy Environment check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahplant/Library/Python/3.9/lib/python/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/Users/noahplant/Library/Python/3.9/lib/python/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Instantiate the environment\n",
    "env = QubitMoverEnv()\n",
    "env_easy=QubitMoverEnv_easy()\n",
    "\n",
    "# Check if the environment follows the Gymnasium API and is compatible with Stable Baselines3\n",
    "check_env(env, warn=True)\n",
    "print(\"Hard Environment check passed!\")\n",
    "check_env(env_easy, warn=True)\n",
    "\n",
    "\n",
    "print(\"Easy Environment check passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29331f",
   "metadata": {},
   "source": [
    "### Create the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b1d6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Create and train the RL agent using PPO\n",
    "\n",
    "# Instantiate the environment\n",
    "env_easy = QubitMoverEnv_easy()\n",
    "\n",
    "# Create the PPO agent\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",      # Use a multilayer perceptron policy\n",
    "    env_easy,              # Pass your custom environment\n",
    "    verbose=1,        # Print training progress\n",
    "    tensorboard_log=\"./ppo_qubit_mover2_tensorboard/\"  # Optional: log for TensorBoard\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8ccee",
   "metadata": {},
   "source": [
    "### Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4aa447ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_qubit_mover2_tensorboard/PPO_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.81     |\n",
      "|    ep_rew_mean     | -0.955   |\n",
      "| time/              |          |\n",
      "|    fps             | 2579     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81        |\n",
      "|    ep_rew_mean          | -0.955      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1909        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018154606 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.69       |\n",
      "|    explained_variance   | -2.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0707     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0501     |\n",
      "|    value_loss           | 0.0909      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53        |\n",
      "|    ep_rew_mean          | -0.915      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1798        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021969907 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.65       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0695     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.067      |\n",
      "|    value_loss           | 0.0293      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.7         |\n",
      "|    ep_rew_mean          | -0.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1739        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037081756 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.59       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0798     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0771     |\n",
      "|    value_loss           | 0.0243      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.58        |\n",
      "|    ep_rew_mean          | -0.69       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1706        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.088379666 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.46       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.113      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0939     |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.03        |\n",
      "|    ep_rew_mean          | -0.665      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1689        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029393537 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.42       |\n",
      "|    explained_variance   | -0.133      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0959     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0859     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.01        |\n",
      "|    ep_rew_mean          | -0.555      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1672        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031242138 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.36       |\n",
      "|    explained_variance   | -0.0944     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0928     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0742     |\n",
      "|    value_loss           | 0.0103      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.64        |\n",
      "|    ep_rew_mean          | -0.52       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1662        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022443932 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.32       |\n",
      "|    explained_variance   | -0.395      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0881     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0547     |\n",
      "|    value_loss           | 0.00632     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.73        |\n",
      "|    ep_rew_mean          | -0.515      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1657        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021451391 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.31       |\n",
      "|    explained_variance   | -0.952      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0957     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0545     |\n",
      "|    value_loss           | 0.00276     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1653        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023305915 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.28       |\n",
      "|    explained_variance   | -1.07       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.104      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0587     |\n",
      "|    value_loss           | 0.00153     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.91       |\n",
      "|    ep_rew_mean          | -0.505     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1649       |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01899203 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.27      |\n",
      "|    explained_variance   | -0.0923    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0863    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0521    |\n",
      "|    value_loss           | 0.00777    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.66        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1647        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020238314 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.25       |\n",
      "|    explained_variance   | -1.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.094      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0567     |\n",
      "|    value_loss           | 0.00125     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.85       |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1645       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 16         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02169767 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.23      |\n",
      "|    explained_variance   | -0.458     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0986    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0593    |\n",
      "|    value_loss           | 0.00137    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.93       |\n",
      "|    ep_rew_mean          | -0.495     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1643       |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02243637 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.18      |\n",
      "|    explained_variance   | -0.29      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0472    |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0545    |\n",
      "|    value_loss           | 0.00145    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.6         |\n",
      "|    ep_rew_mean          | -0.515      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1641        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021568675 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.16       |\n",
      "|    explained_variance   | -0.177      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0818     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.92        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1640        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020849101 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | -0.328      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0448     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0563     |\n",
      "|    value_loss           | 0.000979    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.81        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1641        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023494959 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | -0.12       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0809     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0578     |\n",
      "|    value_loss           | 0.00066     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.85       |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1639       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02086381 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.08      |\n",
      "|    explained_variance   | -0.0482    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0404    |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0513    |\n",
      "|    value_loss           | 0.00141    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 9.75      |\n",
      "|    ep_rew_mean          | -0.505    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1637      |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0211038 |\n",
      "|    clip_fraction        | 0.24      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -7.07     |\n",
      "|    explained_variance   | -0.054    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0395   |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -0.0542   |\n",
      "|    value_loss           | 0.00131   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1636        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020092234 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.05       |\n",
      "|    explained_variance   | -0.118      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0837     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0537     |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.82        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1635        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024208777 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.04       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0834     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0612     |\n",
      "|    value_loss           | 0.000276    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.81        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1634        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021521986 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00797    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0504     |\n",
      "|    value_loss           | 0.00905     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1634        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020929601 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | -1.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0968     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    value_loss           | 0.000811    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1634        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022690367 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | -0.00659    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0869     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0579     |\n",
      "|    value_loss           | 0.000416    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1634        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021705715 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0816     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0594     |\n",
      "|    value_loss           | 0.000388    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.91       |\n",
      "|    ep_rew_mean          | -0.505     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1634       |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02180593 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.95      |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0697    |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0524    |\n",
      "|    value_loss           | 9.36e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.82        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1633        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022434276 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.92       |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.072      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0629     |\n",
      "|    value_loss           | 0.000217    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.95        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1633        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026800461 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.9        |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.112      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.064      |\n",
      "|    value_loss           | 0.000361    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1632        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024435904 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.87       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0624     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0486     |\n",
      "|    value_loss           | 0.000532    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1632        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025897622 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.83       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.102      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0615     |\n",
      "|    value_loss           | 0.000377    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1630        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024441069 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.8        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0935     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0604     |\n",
      "|    value_loss           | 5.36e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1630        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022707965 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.79       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.104      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.063      |\n",
      "|    value_loss           | 0.000196    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.83       |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1627       |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02203359 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.79      |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0859    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0487    |\n",
      "|    value_loss           | 0.00103    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1626       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 42         |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02361288 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.75      |\n",
      "|    explained_variance   | 0.0642     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.103     |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0553    |\n",
      "|    value_loss           | 0.000686   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1626        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026324507 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.72       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0975     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    value_loss           | 0.000203    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1626        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022744033 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.7        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0917     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.062      |\n",
      "|    value_loss           | 0.000188    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1626        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023048008 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.68       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.077      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0585     |\n",
      "|    value_loss           | 0.00018     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1626        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027012125 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.64       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0744     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    value_loss           | 2.68e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.9         |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024770487 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.65       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.093      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0628     |\n",
      "|    value_loss           | 0.00018     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024613936 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.63       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0828     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0463     |\n",
      "|    value_loss           | 0.00106     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1625       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 51         |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02623672 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.59      |\n",
      "|    explained_variance   | 0.062      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0591    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0598    |\n",
      "|    value_loss           | 0.000344   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027357817 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.56       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0651     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0564     |\n",
      "|    value_loss           | 2.67e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023524143 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.54       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.114      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0667     |\n",
      "|    value_loss           | 1.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023194343 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.49       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.1        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0622     |\n",
      "|    value_loss           | 0.000173    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.94        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025798196 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.45       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0623     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0548     |\n",
      "|    value_loss           | 1.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022741273 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.46       |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0827     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0561     |\n",
      "|    value_loss           | 0.000436    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.82        |\n",
      "|    ep_rew_mean          | -0.51       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025583174 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.44       |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    value_loss           | 0.000702    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029178802 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.4        |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0978     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0596     |\n",
      "|    value_loss           | 0.000329    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022706997 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.39       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0636     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 2.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023437139 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.35       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0824     |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0628     |\n",
      "|    value_loss           | 1.15e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.92       |\n",
      "|    ep_rew_mean          | -0.495     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1624       |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 104448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02603324 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.33      |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.106     |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0667    |\n",
      "|    value_loss           | 1e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.99        |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023632737 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.29       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.11       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.056      |\n",
      "|    value_loss           | 0.000531    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1625        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025143009 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.28       |\n",
      "|    explained_variance   | -0.033      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0973     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0627     |\n",
      "|    value_loss           | 3.52e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1624       |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02721035 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.27      |\n",
      "|    explained_variance   | 0.912      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.104     |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.0691    |\n",
      "|    value_loss           | 1.3e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022884402 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.24       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.094      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0648     |\n",
      "|    value_loss           | 9.86e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026736028 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.22       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0818     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0658     |\n",
      "|    value_loss           | 9.48e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025431551 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.2        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.114      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0678     |\n",
      "|    value_loss           | 8.36e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023680313 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.19       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.12       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0667     |\n",
      "|    value_loss           | 0.000175    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.91       |\n",
      "|    ep_rew_mean          | -0.505     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1624       |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 74         |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02986217 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.14      |\n",
      "|    explained_variance   | 0.814      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0386    |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0476    |\n",
      "|    value_loss           | 1.22e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1624        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024705462 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.11       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0952     |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    value_loss           | 0.000841    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1623        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026901461 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.09       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0836     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0476     |\n",
      "|    value_loss           | 0.000176    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1623        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027196424 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.02       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0197     |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 0.000571    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.96        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023175742 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.99       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.065      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0547     |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022645304 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.092      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0549     |\n",
      "|    value_loss           | 0.00063     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025883121 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.98       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0986     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0583     |\n",
      "|    value_loss           | 0.000558    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026752967 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6          |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0856     |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0633     |\n",
      "|    value_loss           | 1.91e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1622       |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 84         |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02711603 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.96      |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0878    |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0659    |\n",
      "|    value_loss           | 1.01e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028524585 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.96       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.11       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0683     |\n",
      "|    value_loss           | 8.26e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025499728 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.94       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.09       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0624     |\n",
      "|    value_loss           | 9.43e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027468804 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.91       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0878     |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0686     |\n",
      "|    value_loss           | 7.62e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1621       |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02371005 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.9       |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.124     |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.0532    |\n",
      "|    value_loss           | 0.000782   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.91        |\n",
      "|    ep_rew_mean          | -0.505      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1622        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028987896 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.114      |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0641     |\n",
      "|    value_loss           | 1.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025711417 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0731     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0624     |\n",
      "|    value_loss           | 0.000322    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028203668 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0606     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 8.75e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025610024 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0987     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0693     |\n",
      "|    value_loss           | 6.03e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024795368 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0996     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0671     |\n",
      "|    value_loss           | 7.06e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027562816 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0696     |\n",
      "|    value_loss           | 6.25e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025396489 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0982     |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0675     |\n",
      "|    value_loss           | 5.7e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1621        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025655076 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0807     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0664     |\n",
      "|    value_loss           | 5.99e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022739418 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0857     |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0516     |\n",
      "|    value_loss           | 0.000763    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | -0.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1620       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 165888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02700526 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.62      |\n",
      "|    explained_variance   | 0.673      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0745    |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0548    |\n",
      "|    value_loss           | 2.3e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023616603 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0875     |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0541     |\n",
      "|    value_loss           | 0.00811     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024628822 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.63       |\n",
      "|    explained_variance   | -4.68       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0886     |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0522     |\n",
      "|    value_loss           | 0.000204    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024060514 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.59       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.038      |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 10        |\n",
      "|    ep_rew_mean          | -0.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1620      |\n",
      "|    iterations           | 85        |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 174080    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0259342 |\n",
      "|    clip_fraction        | 0.27      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -5.57     |\n",
      "|    explained_variance   | 0.632     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0635   |\n",
      "|    n_updates            | 840       |\n",
      "|    policy_gradient_loss | -0.0552   |\n",
      "|    value_loss           | 3.86e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026694793 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0956     |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0617     |\n",
      "|    value_loss           | 1.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023699693 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.56       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.088      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0588     |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026212256 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.104      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0671     |\n",
      "|    value_loss           | 1.08e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.95        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024903359 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0867     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0521     |\n",
      "|    value_loss           | 0.000548    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10          |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025007756 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.51       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0748     |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0448     |\n",
      "|    value_loss           | 0.00093     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.97        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1619        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029473668 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.47       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0691     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0417     |\n",
      "|    value_loss           | 2.17e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.95        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1619        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028819952 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.46       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0536     |\n",
      "|    value_loss           | 0.00065     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.9         |\n",
      "|    ep_rew_mean          | -0.49       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1619        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025989614 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0774     |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 0.00093     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.97        |\n",
      "|    ep_rew_mean          | -0.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1620        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029483655 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.0924      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0488     |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.95        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1619        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026866525 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.38       |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    value_loss           | 0.00749     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.96        |\n",
      "|    ep_rew_mean          | -0.495      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1619        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023033898 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | -0.0457     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0808     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0428     |\n",
      "|    value_loss           | 0.00053     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m eval_callback \u001b[38;5;241m=\u001b[39m EvalCallback(\n\u001b[1;32m      6\u001b[0m     env_easy,\n\u001b[1;32m      7\u001b[0m     eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m      8\u001b[0m     best_model_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/best_model/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400_000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You can increase timesteps for better training\u001b[39;00m\n\u001b[1;32m     18\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/on_policy_algorithm.py:337\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdump_logs(iteration)\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/ppo/ppo.py:278\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    237\u001b[0m         group,\n\u001b[1;32m    238\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         state_steps,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adam.py:525\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    523\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 525\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    527\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize evaluation callback\n",
    "# Create a callback that stops training when mean reward > threshold\n",
    "\n",
    "# Evaluate every 1000 steps, use stop_callback to halt training\n",
    "eval_callback = EvalCallback(\n",
    "    env_easy,\n",
    "    eval_freq=1000,\n",
    "    best_model_save_path='/best_model/',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=400_000)  # You can increase timesteps for better training\n",
    "\n",
    "\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(f\"agents_2/ppo_qubit_mover_agent_{timestamp}\")\n",
    "\n",
    "\n",
    "# To load and use the agent later:\n",
    "# model = PPO.load(\"ppo_qubit_mover_agent\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa024f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
